"""
ML ê¸°ë°˜ ì•ˆì „ ê°€ì¤‘ì¹˜ í•™ìŠµ ëª¨ë“ˆ (ìƒí™œì¸êµ¬ í¬í•¨ ë²„ì „)
- í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê°•í™” (ë°€ë„, ê±°ë¦¬, ê³ ë¦½ë„)
- ìƒí™œì¸êµ¬ ë°ì´í„° í†µí•©
- ë³µí•© ìœ„í—˜ ì§€í‘œ
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Tuple, Optional, List
import pickle
import warnings
warnings.filterwarnings('ignore')

try:
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
    import xgboost as xgb
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    print("âš ï¸ ML íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜: pip install scikit-learn xgboost")

try:
    import networkx as nx
    from scipy.spatial import cKDTree
    GRAPH_AVAILABLE = True
except ImportError:
    GRAPH_AVAILABLE = False


# í”„ë¡œì íŠ¸ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
PROCESSED_DIR = DATA_DIR / "processed"
MODEL_DIR = PROJECT_ROOT / "models"


# ============================================
# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë“¤
# ============================================

def load_crime_data() -> pd.DataFrame:
    """ê²½ì°°ì²­ ë²”ì£„ í†µê³„ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    filepath = DATA_DIR / "ê²½ì°°ì²­_ë²”ì£„ ë°œìƒ ì§€ì—­ë³„ í†µê³„_20241231.csv"
    
    if not filepath.exists():
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {filepath}")
        return pd.DataFrame()
    
    df = pd.read_csv(filepath, encoding='cp949')
    columns = df.columns.tolist()
    
    seoul_columns = [col for col in columns[2:] if 'ì„œìš¸' in col or 'ì„œ ìš¸' in col]
    
    if not seoul_columns:
        return pd.DataFrame()
    
    crime_by_district = {}
    for col in seoul_columns:
        district = col.replace('ì„œìš¸ ', '').replace('ì„œ ìš¸ ', '').strip()
        try:
            total_crimes = pd.to_numeric(df[col], errors='coerce').sum()
            crime_by_district[district] = int(total_crimes)
        except:
            continue
    
    result = pd.DataFrame([
        {'district': k, 'total_crimes': v}
        for k, v in crime_by_district.items()
    ])
    
    if len(result) > 0:
        max_crimes = result['total_crimes'].max()
        min_crimes = result['total_crimes'].min()
        result['danger_label'] = (result['total_crimes'] - min_crimes) / (max_crimes - min_crimes)
    
    print(f"âœ… ì„œìš¸ì‹œ ë²”ì£„ ë°ì´í„°: {len(result)} êµ¬")
    return result


def load_crime_time_data() -> Dict[str, float]:
    """
    ë²”ì£„ ë°œìƒ ì‹œê°„ëŒ€ë³„ ë°ì´í„° ë¡œë“œ
    ë°˜í™˜: ì‹œê°„ëŒ€ë³„ ìœ„í—˜ë„ ë°°ìœ¨ (0~1 ì •ê·œí™”)
    """
    # ì‹œê°„ëŒ€ë³„ íŒŒì¼ ì°¾ê¸°
    time_files = list(DATA_DIR.glob("ë²”ì£„ë°œìƒ_ì‹œê°„_*.csv"))
    
    if not time_files:
        print("âš ï¸ ë²”ì£„ ì‹œê°„ëŒ€ íŒŒì¼ ì—†ìŒ")
        return get_default_time_danger()
    
    filepath = time_files[0]
    
    # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
    df = None
    for encoding in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr', 'latin1']:
        try:
            df = pd.read_csv(filepath, encoding=encoding, header=[0, 1])
            break
        except:
            continue
    
    if df is None:
        print("âš ï¸ ë²”ì£„ ì‹œê°„ëŒ€ íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜")
        return get_default_time_danger()
    
    try:
        # ì‹œê°„ëŒ€ë³„ ë²”ì£„ ê±´ìˆ˜
        time_slots = {
            '00:00-02:59': 0, '03:00-05:59': 0, '06:00-08:59': 0,
            '09:00-11:59': 0, '12:00-14:59': 0, '15:00-17:59': 0,
            '18:00-20:59': 0, '21:00-23:59': 0
        }
        
        for col in df.columns:
            col_str = str(col[1]) if isinstance(col, tuple) else str(col)
            for slot in time_slots.keys():
                if slot in col_str:
                    try:
                        val = pd.to_numeric(df.iloc[0][col], errors='coerce')
                        if pd.notna(val):
                            time_slots[slot] += val
                    except:
                        pass
        
        if sum(time_slots.values()) > 0:
            max_val = max(time_slots.values())
            min_val = min(time_slots.values())
            
            time_danger = {}
            for slot, val in time_slots.items():
                time_danger[slot] = (val - min_val) / (max_val - min_val) if max_val > min_val else 0.5
            
            print(f"âœ… ë²”ì£„ ì‹œê°„ëŒ€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            for slot, danger in sorted(time_danger.items()):
                print(f"   {slot}: {danger:.3f}")
            
            return time_danger
    except Exception as e:
        print(f"âš ï¸ ë²”ì£„ ì‹œê°„ëŒ€ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    return get_default_time_danger()


def load_crime_day_data() -> Dict[str, float]:
    """
    ë²”ì£„ ë°œìƒ ìš”ì¼ë³„ ë°ì´í„° ë¡œë“œ
    ë°˜í™˜: ìš”ì¼ë³„ ìœ„í—˜ë„ ë°°ìœ¨ (0~1 ì •ê·œí™”)
    """
    # ìš”ì¼ë³„ íŒŒì¼ ì°¾ê¸°
    day_files = list(DATA_DIR.glob("ë²”ì£„ë°œìƒ_ìš”ì¼_*.csv"))
    
    if not day_files:
        print("âš ï¸ ë²”ì£„ ìš”ì¼ íŒŒì¼ ì—†ìŒ")
        return get_default_day_danger()
    
    filepath = day_files[0]
    
    # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
    df = None
    for encoding in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr', 'latin1']:
        try:
            df = pd.read_csv(filepath, encoding=encoding, header=[0, 1])
            break
        except:
            continue
    
    if df is None:
        print("âš ï¸ ë²”ì£„ ìš”ì¼ íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜")
        return get_default_day_danger()
    
    try:
        # ìš”ì¼ë³„ ë²”ì£„ ê±´ìˆ˜
        day_mapping = {
            'ì›”': 'monday', 'í™”': 'tuesday', 'ìˆ˜': 'wednesday',
            'ëª©': 'thursday', 'ê¸ˆ': 'friday', 'í† ': 'saturday', 'ì¼': 'sunday'
        }
        
        day_counts = {day: 0 for day in day_mapping.values()}
        
        for col in df.columns:
            col_str = str(col[1]) if isinstance(col, tuple) else str(col)
            for kor, eng in day_mapping.items():
                if kor in col_str and 'í•©ê³„' not in col_str:
                    try:
                        val = pd.to_numeric(df.iloc[0][col], errors='coerce')
                        if pd.notna(val):
                            day_counts[eng] += val
                    except:
                        pass
        
        if sum(day_counts.values()) > 0:
            max_val = max(day_counts.values())
            min_val = min(day_counts.values())
            
            day_danger = {}
            for day, val in day_counts.items():
                day_danger[day] = (val - min_val) / (max_val - min_val) if max_val > min_val else 0.5
            
            print(f"âœ… ë²”ì£„ ìš”ì¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            for day, danger in day_danger.items():
                print(f"   {day}: {danger:.3f}")
            
            return day_danger
    except Exception as e:
        print(f"âš ï¸ ë²”ì£„ ìš”ì¼ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    return get_default_day_danger()


def get_default_time_danger() -> Dict[str, float]:
    """ê¸°ë³¸ ì‹œê°„ëŒ€ë³„ ìœ„í—˜ë„ (ë°ì´í„° ì—†ì„ ë•Œ)"""
    return {
        '00:00-02:59': 0.9,   # ìƒˆë²½: ë§¤ìš° ìœ„í—˜
        '03:00-05:59': 0.8,   # ìƒˆë²½: ìœ„í—˜
        '06:00-08:59': 0.3,   # ì•„ì¹¨: ì•ˆì „
        '09:00-11:59': 0.2,   # ì˜¤ì „: ì•ˆì „
        '12:00-14:59': 0.3,   # ì ì‹¬: ì•ˆì „
        '15:00-17:59': 0.4,   # ì˜¤í›„: ë³´í†µ
        '18:00-20:59': 0.6,   # ì €ë…: ì£¼ì˜
        '21:00-23:59': 0.8,   # ë°¤: ìœ„í—˜
    }


def get_default_day_danger() -> Dict[str, float]:
    """ê¸°ë³¸ ìš”ì¼ë³„ ìœ„í—˜ë„ (ë°ì´í„° ì—†ì„ ë•Œ)"""
    return {
        'monday': 0.4, 'tuesday': 0.4, 'wednesday': 0.4,
        'thursday': 0.5, 'friday': 0.7, 'saturday': 0.8, 'sunday': 0.6
    }


def get_time_danger_score(hour: int, time_danger: Dict[str, float]) -> float:
    """ì‹œê°„(0-23)ì— í•´ë‹¹í•˜ëŠ” ìœ„í—˜ë„ ë°˜í™˜"""
    if 0 <= hour < 3:
        return time_danger.get('00:00-02:59', 0.9)
    elif 3 <= hour < 6:
        return time_danger.get('03:00-05:59', 0.8)
    elif 6 <= hour < 9:
        return time_danger.get('06:00-08:59', 0.3)
    elif 9 <= hour < 12:
        return time_danger.get('09:00-11:59', 0.2)
    elif 12 <= hour < 15:
        return time_danger.get('12:00-14:59', 0.3)
    elif 15 <= hour < 18:
        return time_danger.get('15:00-17:59', 0.4)
    elif 18 <= hour < 21:
        return time_danger.get('18:00-20:59', 0.6)
    else:
        return time_danger.get('21:00-23:59', 0.8)


def get_day_danger_score(day: int, day_danger: Dict[str, float]) -> float:
    """ìš”ì¼(0=ì›”~6=ì¼)ì— í•´ë‹¹í•˜ëŠ” ìœ„í—˜ë„ ë°˜í™˜"""
    days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']
    return day_danger.get(days[day % 7], 0.5)


def load_streetlight_schedule() -> Dict[str, int]:
    """ê°€ë¡œë“± ì ì†Œë“± ì‹œê°„ ë¡œë“œ"""
    filepath = DATA_DIR / "ì„œìš¸ì‹œ ê°€ë¡œë“± ì ì†Œë“± ì‹œê°„ í˜„í™©.csv"
    
    if not filepath.exists():
        print("âš ï¸ ê°€ë¡œë“± ì ì†Œë“± ì‹œê°„ íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš© (18:00~06:00)")
        return {'on_hour': 18, 'off_hour': 6}
    
    try:
        df = pd.read_csv(filepath, encoding='cp949')
        
        def parse_time(t):
            if pd.isna(t):
                return None
            return int(t) // 10000  # HHMMSS -> HH
        
        on_times = df['ì„œìš¸ì‹œ ì‹¤ì œ ì ë“±ì‹œê°„(ì‹œë¶„ì´ˆ)'].apply(parse_time).dropna()
        off_times = df['ì„œìš¸ì‹œ ì‹¤ì œ ì†Œë“±ì‹œê°„(ì‹œë¶„ì´ˆ)'].apply(parse_time).dropna()
        
        avg_on = int(on_times.mean()) if len(on_times) > 0 else 18
        avg_off = int(off_times.mean()) if len(off_times) > 0 else 6
        
        print(f"âœ… ê°€ë¡œë“± ì ì†Œë“± ì‹œê°„: ì ë“± {avg_on}ì‹œ, ì†Œë“± {avg_off}ì‹œ")
        return {'on_hour': avg_on, 'off_hour': avg_off}
        
    except Exception as e:
        print(f"âš ï¸ ê°€ë¡œë“± ì ì†Œë“± ì‹œê°„ íŒŒì¼ ì˜¤ë¥˜: {e}")
        return {'on_hour': 18, 'off_hour': 6}


def is_streetlight_on(hour: int, schedule: Dict[str, int]) -> bool:
    """í˜„ì¬ ì‹œê°„ì— ê°€ë¡œë“±ì´ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸"""
    on_hour = schedule.get('on_hour', 18)
    off_hour = schedule.get('off_hour', 6)
    
    # ì ë“±: 18ì‹œ, ì†Œë“±: 6ì‹œì¸ ê²½ìš°
    # 18~23ì‹œ, 0~5ì‹œ = ê°€ë¡œë“± ON
    if on_hour > off_hour:  # ì €ë…~ì•„ì¹¨ (ì¼ë°˜ì ì¸ ê²½ìš°)
        return hour >= on_hour or hour < off_hour
    else:  # ì˜ˆì™¸ ì¼€ì´ìŠ¤
        return on_hour <= hour < off_hour


def load_population_data() -> pd.DataFrame:
    """ìƒí™œì¸êµ¬ ë°ì´í„° ë¡œë“œ"""
    filepath = DATA_DIR / "all_months_monthly_avg_with_dong.csv"
    
    if not filepath.exists():
        print(f"âš ï¸ ìƒí™œì¸êµ¬ íŒŒì¼ ì—†ìŒ: {filepath}")
        return pd.DataFrame()
    
    # ì¸ì½”ë”© ì‹œë„
    for encoding in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']:
        try:
            df = pd.read_csv(filepath, encoding=encoding)
            break
        except:
            continue
    else:
        print("âŒ ìƒí™œì¸êµ¬ íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜")
        return pd.DataFrame()
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    df.columns = [col.strip() for col in df.columns]
    
    # ì»¬ëŸ¼ëª… ë§¤í•‘ (ë‹¤ì–‘í•œ í˜•ì‹ ëŒ€ì‘)
    column_mapping = {}
    for col in df.columns:
        col_lower = col.lower()
        if 'ë™ì½”ë“œ' in col or 'í–‰ì •ë™ì½”ë“œ' in col or 'code' in col_lower:
            column_mapping[col] = 'dong_code'
        elif 'ë™' in col and 'ì¸êµ¬' not in col:
            column_mapping[col] = 'dong_name'
        elif 'ìƒí™œì¸êµ¬' in col or 'ì¸êµ¬' in col or 'population' in col_lower:
            column_mapping[col] = 'population'
        elif 'month' in col_lower or 'ì›”' in col:
            column_mapping[col] = 'month'
    
    df = df.rename(columns=column_mapping)
    
    # ë™ë³„ í‰ê·  ì¸êµ¬ ê³„ì‚° (ì›”ë³„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
    if 'month' in df.columns and 'dong_code' in df.columns:
        df = df.groupby('dong_code').agg({
            'dong_name': 'first',
            'population': 'mean'
        }).reset_index()
    
    # ì¸êµ¬ ì •ê·œí™” (0~1)
    if 'population' in df.columns and len(df) > 0:
        pop_max = df['population'].max()
        pop_min = df['population'].min()
        df['population_normalized'] = (df['population'] - pop_min) / (pop_max - pop_min)
        
        print(f"âœ… ìƒí™œì¸êµ¬ ë°ì´í„°: {len(df)} ë™")
        print(f"   ì¸êµ¬ ë²”ìœ„: {pop_min:,.0f} ~ {pop_max:,.0f}")
    
    return df


def get_district_from_coords(lat: float, lon: float) -> str:
    """ì¢Œí‘œë¡œë¶€í„° êµ¬ ì´ë¦„ ì¶”ì •"""
    districts = {
        'ê°•ë‚¨êµ¬': (37.5172, 127.0473), 'ê°•ë™êµ¬': (37.5301, 127.1238),
        'ê°•ë¶êµ¬': (37.6396, 127.0255), 'ê°•ì„œêµ¬': (37.5509, 126.8495),
        'ê´€ì•…êµ¬': (37.4784, 126.9516), 'ê´‘ì§„êµ¬': (37.5384, 127.0823),
        'êµ¬ë¡œêµ¬': (37.4954, 126.8874), 'ê¸ˆì²œêµ¬': (37.4519, 126.9020),
        'ë…¸ì›êµ¬': (37.6542, 127.0568), 'ë„ë´‰êµ¬': (37.6688, 127.0471),
        'ë™ëŒ€ë¬¸êµ¬': (37.5744, 127.0400), 'ë™ì‘êµ¬': (37.5124, 126.9393),
        'ë§ˆí¬êµ¬': (37.5663, 126.9014), 'ì„œëŒ€ë¬¸êµ¬': (37.5791, 126.9368),
        'ì„œì´ˆêµ¬': (37.4837, 127.0324), 'ì„±ë™êµ¬': (37.5633, 127.0371),
        'ì„±ë¶êµ¬': (37.5894, 127.0167), 'ì†¡íŒŒêµ¬': (37.5145, 127.1059),
        'ì–‘ì²œêµ¬': (37.5169, 126.8664), 'ì˜ë“±í¬êµ¬': (37.5264, 126.8963),
        'ìš©ì‚°êµ¬': (37.5324, 126.9907), 'ì€í‰êµ¬': (37.6027, 126.9291),
        'ì¢…ë¡œêµ¬': (37.5735, 126.9790), 'ì¤‘êµ¬': (37.5641, 126.9979),
        'ì¤‘ë‘êµ¬': (37.6063, 127.0925),
    }
    
    min_dist = float('inf')
    closest = 'ê°•ë‚¨êµ¬'
    for district, (d_lat, d_lon) in districts.items():
        dist = ((lat - d_lat) ** 2 + (lon - d_lon) ** 2) ** 0.5
        if dist < min_dist:
            min_dist = dist
            closest = district
    return closest


def get_dong_code_from_coords(lat: float, lon: float, population_data: pd.DataFrame) -> str:
    """ì¢Œí‘œë¡œë¶€í„° ê°€ì¥ ê°€ê¹Œìš´ ë™ ì½”ë“œ ë°˜í™˜"""
    if len(population_data) == 0 or 'dong_code' not in population_data.columns:
        return None
    
    # ë™ ì½”ë“œì—ì„œ êµ¬ ì½”ë“œ ì¶”ì¶œí•˜ì—¬ ë§¤ì¹­ (ê°„ë‹¨í•œ êµ¬í˜„)
    district = get_district_from_coords(lat, lon)
    
    # í•´ë‹¹ êµ¬ì˜ ë™ë“¤ ì¤‘ ëœë¤ ì„ íƒ (ì‹¤ì œë¡œëŠ” í–‰ì •ë™ ê²½ê³„ ë°ì´í„° í•„ìš”)
    return population_data['dong_code'].iloc[np.random.randint(len(population_data))]


# ============================================
# í–¥ìƒëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ìƒí™œì¸êµ¬ í¬í•¨)
# ============================================

class EnhancedFeatureExtractor:
    """
    í–¥ìƒëœ í”¼ì²˜ ì¶”ì¶œê¸° (ìƒí™œì¸êµ¬ í¬í•¨)
    """
    
    def __init__(self, facilities: Dict[str, pd.DataFrame], 
                 population_data: pd.DataFrame = None):
        self.facilities = facilities
        self.population_data = population_data
        self.trees = {}
        self._build_spatial_indices()
        
        # ìƒí™œì¸êµ¬ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        self.population_dict = {}
        if population_data is not None and len(population_data) > 0:
            if 'dong_code' in population_data.columns:
                self.population_dict = dict(zip(
                    population_data['dong_code'].astype(str),
                    population_data['population_normalized']
                ))
            if 'dong_name' in population_data.columns:
                name_dict = dict(zip(
                    population_data['dong_name'],
                    population_data['population_normalized']
                ))
                self.population_dict.update(name_dict)
    
    def _build_spatial_indices(self):
        """ê³µê°„ ì¸ë±ìŠ¤ ìƒì„±"""
        for key, df in self.facilities.items():
            if len(df) > 0 and 'latitude' in df.columns:
                coords = df[['latitude', 'longitude']].values
                self.trees[key] = cKDTree(coords)
                print(f"   âœ… {key}: {len(coords):,} ì¢Œí‘œ ì¸ë±ì‹±")
            else:
                self.trees[key] = None
    
    def count_facilities(self, point: np.ndarray, facility_type: str, 
                         radius_m: float = 50) -> int:
        """ë°˜ê²½ ë‚´ ì‹œì„¤ë¬¼ ê°œìˆ˜"""
        tree = self.trees.get(facility_type)
        if tree is None:
            return 0
        radius_deg = radius_m / 111000
        return len(tree.query_ball_point(point, radius_deg))
    
    def nearest_distance(self, point: np.ndarray, facility_type: str) -> float:
        """ê°€ì¥ ê°€ê¹Œìš´ ì‹œì„¤ë¬¼ê¹Œì§€ ê±°ë¦¬ (ë¯¸í„°)"""
        tree = self.trees.get(facility_type)
        if tree is None:
            return 1000.0
        
        dist_deg, _ = tree.query(point)
        return dist_deg * 111000
    
    def get_population_score(self, dong_code: str = None, dong_name: str = None) -> float:
        """ë™ì˜ ìƒí™œì¸êµ¬ ì ìˆ˜ (0~1, ë†’ì„ìˆ˜ë¡ ì¸êµ¬ ë§ìŒ)"""
        if dong_code and str(dong_code) in self.population_dict:
            return self.population_dict[str(dong_code)]
        if dong_name and dong_name in self.population_dict:
            return self.population_dict[dong_name]
        return 0.5  # ê¸°ë³¸ê°’
    
    def extract_features(self, lat: float, lon: float, road_length: float = 100,
                         is_main_road: bool = False, dong_code: str = None,
                         dong_name: str = None, hour: int = None) -> Dict:
        """í–¥ìƒëœ í”¼ì²˜ ì¶”ì¶œ (ìƒí™œì¸êµ¬ + ë„ë¡œ í”¼ì²˜ í¬í•¨)"""
        point = np.array([lat, lon])
        
        # ===== ê¸°ë³¸ í”¼ì²˜: ê°œìˆ˜ =====
        streetlight_count = self.count_facilities(point, 'streetlight', 50)
        cctv_count = self.count_facilities(point, 'cctv', 50)
        convenience_count = self.count_facilities(point, 'convenience', 100)
        entertainment_count = self.count_facilities(point, 'entertainment', 100)
        police_count = self.count_facilities(point, 'police', 500)
        school_count = self.count_facilities(point, 'school', 300)  # í•™êµ 300m ë°˜ê²½
        child_zone_count = self.count_facilities(point, 'child_zone', 200)  # ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­ 200m
        
        # ===== ë„ë³´ ë„¤íŠ¸ì›Œí¬ í”¼ì²˜: íš¡ë‹¨ë³´ë„/ê³µì›/í„°ë„ =====
        crosswalk_count = self.count_facilities(point, 'crosswalk', 100)  # íš¡ë‹¨ë³´ë„ 100m
        park_count = self.count_facilities(point, 'park', 100)  # ê³µì›/ë…¹ì§€ 100m
        tunnel_count = self.count_facilities(point, 'tunnel', 100)  # í„°ë„ 100m
        
        # ===== ë°€ë„ í”¼ì²˜ =====
        length_factor = max(road_length, 10) / 100
        streetlight_density = streetlight_count / length_factor
        cctv_density = cctv_count / length_factor
        convenience_density = convenience_count / length_factor
        entertainment_density = entertainment_count / length_factor
        
        # ===== ê±°ë¦¬ í”¼ì²˜ =====
        def normalize_distance(d, max_d=500):
            return max(0, 1 - d / max_d)
        
        streetlight_proximity = normalize_distance(self.nearest_distance(point, 'streetlight'), 100)
        cctv_proximity = normalize_distance(self.nearest_distance(point, 'cctv'), 200)
        convenience_proximity = normalize_distance(self.nearest_distance(point, 'convenience'), 300)
        police_proximity = normalize_distance(self.nearest_distance(point, 'police'), 1000)
        entertainment_proximity = normalize_distance(self.nearest_distance(point, 'entertainment'), 300)
        
        # ===== ê³ ë¦½ë„ =====
        no_streetlight = 1 if streetlight_count == 0 else 0
        no_cctv = 1 if cctv_count == 0 else 0
        no_convenience = 1 if convenience_count == 0 else 0
        no_police = 1 if police_count == 0 else 0
        
        isolation_score = (no_streetlight + no_cctv + no_convenience + no_police) / 4
        complete_isolation = 1 if (streetlight_count == 0 and cctv_count == 0 
                                   and convenience_count == 0 and police_count == 0) else 0
        
        # ===== ìœ„í—˜/ì•ˆì „ ë¹„ìœ¨ =====
        safety_sum = streetlight_count + cctv_count * 2 + convenience_count + police_count * 3
        danger_sum = entertainment_count * 2
        
        if safety_sum > 0:
            danger_safety_ratio = danger_sum / (safety_sum + danger_sum)
        else:
            danger_safety_ratio = 1.0 if danger_sum > 0 else 0.5
        
        # ===== ë„ë¡œ/ë³µí•© í”¼ì²˜ =====
        road_length_normalized = min(road_length / 500, 1)
        streetlight_coverage = min(streetlight_count / 3, 1)
        night_safety = min((streetlight_count * 0.3 + convenience_count * 0.5 + cctv_count * 0.2) / 3, 1)
        entertainment_danger = min(entertainment_count / 2, 1)
        
        # ===== ìƒí™œì¸êµ¬ í”¼ì²˜ (NEW!) =====
        population_score = self.get_population_score(dong_code, dong_name)
        
        # ì¸êµ¬ ì ì€ ê³³ì€ ì•¼ê°„ì— ë” ìœ„í—˜
        low_population = 1 if population_score < 0.3 else 0
        high_population = 1 if population_score > 0.7 else 0
        
        # ì•¼ê°„ ê³ ë¦½ ì ìˆ˜ (ì¸êµ¬ ì ê³  + ì‹œì„¤ë¬¼ ì—†ìŒ)
        night_isolation = isolation_score * (1 - population_score)
        
        return {
            # ê¸°ë³¸ ê°œìˆ˜ í”¼ì²˜
            'streetlight_count': streetlight_count,
            'cctv_count': cctv_count,
            'convenience_count': convenience_count,
            'entertainment_count': entertainment_count,
            'police_nearby': 1 if police_count > 0 else 0,
            
            # ë°€ë„ í”¼ì²˜
            'streetlight_density': streetlight_density,
            'cctv_density': cctv_density,
            'convenience_density': convenience_density,
            'entertainment_density': entertainment_density,
            
            # ê±°ë¦¬ í”¼ì²˜
            'streetlight_proximity': streetlight_proximity,
            'cctv_proximity': cctv_proximity,
            'convenience_proximity': convenience_proximity,
            'police_proximity': police_proximity,
            'entertainment_proximity': entertainment_proximity,
            
            # ê³ ë¦½ë„
            'isolation_score': isolation_score,
            'complete_isolation': complete_isolation,
            
            # ìœ„í—˜/ì•ˆì „ ë¹„ìœ¨
            'danger_safety_ratio': danger_safety_ratio,
            
            # ë„ë¡œ í”¼ì²˜
            'road_length': road_length_normalized,
            'is_main_road': 1 if is_main_road else 0,
            
            # ë³µí•© í”¼ì²˜
            'streetlight_coverage': streetlight_coverage,
            'night_safety': night_safety,
            'entertainment_danger': entertainment_danger,
            
            # ìƒí™œì¸êµ¬ í”¼ì²˜
            'population_score': population_score,
            'low_population': low_population,
            'high_population': high_population,
            'night_isolation': night_isolation,
            
            # í•™êµ/ì–´ë¦°ì´ ë³´í˜¸êµ¬ì—­ í”¼ì²˜
            'school_nearby': 1 if school_count > 0 else 0,
            'child_zone_nearby': 1 if child_zone_count > 0 else 0,
            'safety_zone_score': min((school_count + child_zone_count) / 2, 1),
            
            # ë„ë³´ ë„¤íŠ¸ì›Œí¬ í”¼ì²˜ (íš¡ë‹¨ë³´ë„/ê³µì›/í„°ë„)
            'crosswalk_nearby': 1 if crosswalk_count > 0 else 0,
            'park_nearby': 1 if park_count > 0 else 0,  # ì•¼ê°„ ìœ„í—˜ ìš”ì†Œ
            'tunnel_nearby': 1 if tunnel_count > 0 else 0,  # ìœ„í—˜ ìš”ì†Œ
            'road_safety_score': min(crosswalk_count / 2, 1) - 0.3 * (1 if park_count > 0 else 0) - 0.5 * (1 if tunnel_count > 0 else 0),
        }


# ============================================
# í–¥ìƒëœ ML ëª¨ë¸ (ìƒí™œì¸êµ¬ í¬í•¨)
# ============================================

class EnhancedSafetyMLModel:
    """í–¥ìƒëœ ì•ˆì „ ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ (ìƒí™œì¸êµ¬ í¬í•¨)"""
    
    BASIC_FEATURES = [
        'streetlight_count', 'cctv_count', 'convenience_count',
        'entertainment_count', 'police_nearby'
    ]
    
    DENSITY_FEATURES = [
        'streetlight_density', 'cctv_density', 
        'convenience_density', 'entertainment_density'
    ]
    
    DISTANCE_FEATURES = [
        'streetlight_proximity', 'cctv_proximity', 'convenience_proximity',
        'police_proximity', 'entertainment_proximity'
    ]
    
    ISOLATION_FEATURES = [
        'isolation_score', 'complete_isolation', 'danger_safety_ratio'
    ]
    
    ROAD_FEATURES = [
        'road_length', 'is_main_road', 'streetlight_coverage',
        'night_safety', 'entertainment_danger'
    ]
    
    # ìƒí™œì¸êµ¬ í”¼ì²˜
    POPULATION_FEATURES = [
        'population_score', 'low_population', 'high_population', 'night_isolation'
    ]
    
    # ì‹œê°„/ìš”ì¼ í”¼ì²˜
    TIME_FEATURES = [
        'hour_danger', 'day_danger', 'is_night', 'is_weekend'
    ]
    
    # í•™êµ/ì–´ë¦°ì´ ë³´í˜¸êµ¬ì—­ í”¼ì²˜
    SAFETY_ZONE_FEATURES = [
        'school_nearby', 'child_zone_nearby', 'safety_zone_score'
    ]
    
    # ë„ë³´ ë„¤íŠ¸ì›Œí¬ í”¼ì²˜ (íš¡ë‹¨ë³´ë„/ê³µì›/í„°ë„)
    ROAD_NETWORK_FEATURES = [
        'crosswalk_nearby', 'park_nearby', 'tunnel_nearby', 'road_safety_score'
    ]
    
    # ê°€ë¡œë“± ì ì†Œë“± í”¼ì²˜
    STREETLIGHT_SCHEDULE_FEATURES = [
        'streetlight_on', 'streetlight_effective_count', 'streetlight_effective_proximity'
    ]
    
    def __init__(self, use_all_features: bool = True, use_population: bool = True,
                 use_time: bool = True, use_safety_zone: bool = True):
        self.model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.feature_importance = {}
        
        self.feature_columns = self.BASIC_FEATURES.copy()
        
        if use_all_features:
            self.feature_columns += self.DENSITY_FEATURES
            self.feature_columns += self.DISTANCE_FEATURES
            self.feature_columns += self.ISOLATION_FEATURES
            self.feature_columns += self.ROAD_FEATURES
        
        if use_population:
            self.feature_columns += self.POPULATION_FEATURES
        
        if use_time:
            self.feature_columns += self.TIME_FEATURES
        
        if use_safety_zone:
            self.feature_columns += self.SAFETY_ZONE_FEATURES
            self.feature_columns += self.ROAD_NETWORK_FEATURES  # ë„ë¡œ ë„¤íŠ¸ì›Œí¬ í”¼ì²˜
            self.feature_columns += self.STREETLIGHT_SCHEDULE_FEATURES  # ê°€ë¡œë“± ì ì†Œë“± í”¼ì²˜
        
        print(f"ğŸ“Š ì‚¬ìš©í•  í”¼ì²˜ ìˆ˜: {len(self.feature_columns)}")
    
    def prepare_features(self, df: pd.DataFrame) -> np.ndarray:
        """í”¼ì²˜ ì¤€ë¹„"""
        features = []
        for col in self.feature_columns:
            if col in df.columns:
                features.append(df[col].fillna(0).values)
            else:
                features.append(np.zeros(len(df)))
        return np.column_stack(features)
    
    def train(self, df: pd.DataFrame, target_col: str = 'danger_label') -> Dict:
        """ëª¨ë¸ í•™ìŠµ"""
        if not ML_AVAILABLE:
            raise ImportError("scikit-learn, xgboost íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        
        print("\n" + "=" * 60)
        print("ğŸ¤– í–¥ìƒëœ ML ëª¨ë¸ í•™ìŠµ (ìƒí™œì¸êµ¬ í¬í•¨)")
        print(f"   í”¼ì²˜ ìˆ˜: {len(self.feature_columns)}")
        print("=" * 60)
        
        X = self.prepare_features(df)
        y = df[target_col].values
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        self.model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.05,
            min_child_weight=3,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            verbosity=0
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        y_pred = self.model.predict(X_test_scaled)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=5, scoring='r2')
        
        print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥:")
        print(f"   - RMSE: {rmse:.4f}")
        print(f"   - MAE: {mae:.4f}")
        print(f"   - RÂ² (í…ŒìŠ¤íŠ¸): {r2:.4f}")
        print(f"   - RÂ² (CV í‰ê· ): {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
        
        self.feature_importance = dict(zip(
            self.feature_columns, 
            self.model.feature_importances_
        ))
        
        print(f"\nğŸ“ˆ í•™ìŠµëœ í”¼ì²˜ ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ):")
        sorted_importance = sorted(self.feature_importance.items(), 
                                   key=lambda x: x[1], reverse=True)[:10]
        for name, imp in sorted_importance:
            bar = 'â–ˆ' * int(imp * 50)
            print(f"   {name:25s}: {imp:.4f} {bar}")
        
        self.is_trained = True
        return {'rmse': rmse, 'mae': mae, 'r2': r2, 'cv_r2': cv_scores.mean()}
    
    def predict(self, df: pd.DataFrame) -> np.ndarray:
        """ìœ„í—˜ë„ ì˜ˆì¸¡"""
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        X = self.prepare_features(df)
        X_scaled = self.scaler.transform(X)
        return np.clip(self.model.predict(X_scaled), 0, 1)
    
    def predict_single(self, **kwargs) -> float:
        """ë‹¨ì¼ ì˜ˆì¸¡"""
        df = pd.DataFrame([kwargs])
        return float(self.predict(df)[0])
    
    def save(self, filename: str = "enhanced_safety_model"):
        """ëª¨ë¸ ì €ì¥"""
        MODEL_DIR.mkdir(exist_ok=True)
        filepath = MODEL_DIR / f"{filename}.pkl"
        
        with open(filepath, 'wb') as f:
            pickle.dump({
                'model': self.model,
                'scaler': self.scaler,
                'feature_columns': self.feature_columns,
                'feature_importance': self.feature_importance,
                'is_trained': self.is_trained
            }, f)
        
        print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥: {filepath}")
    
    def load(self, filename: str = "enhanced_safety_model"):
        """ëª¨ë¸ ë¡œë“œ"""
        filepath = MODEL_DIR / f"{filename}.pkl"
        
        with open(filepath, 'rb') as f:
            data = pickle.load(f)
            self.model = data['model']
            self.scaler = data['scaler']
            self.feature_columns = data['feature_columns']
            self.feature_importance = data['feature_importance']
            self.is_trained = data['is_trained']
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ: {filepath}")


# ê¸°ì¡´ í˜¸í™˜ìš©
SafetyMLModel = EnhancedSafetyMLModel


# ============================================
# í•™ìŠµ ë°ì´í„° ìƒì„±
# ============================================

def load_facility_data() -> Dict[str, pd.DataFrame]:
    """ì‹œì„¤ë¬¼ ë°ì´í„° ë¡œë“œ"""
    facilities = {}
    files = {
        'streetlight': 'streetlights.csv',
        'cctv': 'cctv.csv',
        'police': 'police_stations.csv',
        'convenience': 'convenience_stores.csv',
        'entertainment': 'entertainment_danger.csv',
        'school': 'schools.csv',
        'child_zone': 'child_protection_zones.csv',
        'pedestrian_node': 'pedestrian_nodes.csv'  # ë„ë³´ ë„¤íŠ¸ì›Œí¬ ë…¸ë“œ
    }
    
    for key, filename in files.items():
        filepath = PROCESSED_DIR / filename
        if filepath.exists():
            df = pd.read_csv(filepath)
            facilities[key] = df
        else:
            facilities[key] = pd.DataFrame()
    
    # ë„ë³´ ë§í¬ ë°ì´í„°ë„ ë¡œë“œ (íš¡ë‹¨ë³´ë„, ê³µì›, í„°ë„ ë¶„ì„ìš©)
    links_path = PROCESSED_DIR / 'pedestrian_links.csv'
    if links_path.exists():
        links = pd.read_csv(links_path)
        facilities['pedestrian_links'] = links
        
        # íš¡ë‹¨ë³´ë„/ê³µì›/í„°ë„ ë§í¬ë¥¼ ë…¸ë“œì™€ ì—°ê²°í•˜ì—¬ ì¢Œí‘œ ì¶”ì¶œ
        nodes = facilities.get('pedestrian_node', pd.DataFrame())
        if len(nodes) > 0 and len(links) > 0:
            # íš¡ë‹¨ë³´ë„ ë…¸ë“œ
            crosswalk_ids = links[links['crosswalk'] == 1]['start_node'].unique()
            facilities['crosswalk'] = nodes[nodes['node_id'].isin(crosswalk_ids)][['latitude', 'longitude']].copy()
            
            # ê³µì›/ë…¹ì§€ ë…¸ë“œ (ì•¼ê°„ ìœ„í—˜ ìš”ì†Œ)
            park_ids = links[links['park'] == 1]['start_node'].unique()
            facilities['park'] = nodes[nodes['node_id'].isin(park_ids)][['latitude', 'longitude']].copy()
            
            # í„°ë„ ë…¸ë“œ (ìœ„í—˜ ìš”ì†Œ)
            tunnel_ids = links[links['tunnel'] == 1]['start_node'].unique()
            facilities['tunnel'] = nodes[nodes['node_id'].isin(tunnel_ids)][['latitude', 'longitude']].copy()
            
            print(f"   âœ… íš¡ë‹¨ë³´ë„: {len(facilities['crosswalk']):,} ë…¸ë“œ")
            print(f"   âœ… ê³µì›/ë…¹ì§€: {len(facilities['park']):,} ë…¸ë“œ")
            print(f"   âœ… í„°ë„: {len(facilities['tunnel']):,} ë…¸ë“œ")
    
    return facilities


def generate_training_data(crime_data: pd.DataFrame, 
                           facilities: Dict[str, pd.DataFrame],
                           population_data: pd.DataFrame = None,
                           time_danger: Dict[str, float] = None,
                           day_danger: Dict[str, float] = None,
                           streetlight_schedule: Dict[str, int] = None,
                           n_samples: int = 10000) -> pd.DataFrame:
    """í–¥ìƒëœ í”¼ì²˜ë¡œ í•™ìŠµ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë„ë¡œ ì¢Œí‘œ + ê°€ë¡œë“± ì ì†Œë“± ê¸°ë°˜)"""
    
    print(f"\nğŸ“‚ í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘ ({n_samples} ìƒ˜í”Œ)...")
    
    # í”¼ì²˜ ì¶”ì¶œê¸° ìƒì„± (ìƒí™œì¸êµ¬ í¬í•¨)
    extractor = EnhancedFeatureExtractor(facilities, population_data)
    
    # ì‹œê°„/ìš”ì¼ ìœ„í—˜ë„ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
    if time_danger is None:
        time_danger = get_default_time_danger()
    if day_danger is None:
        day_danger = get_default_day_danger()
    
    districts = crime_data['district'].tolist()
    danger_dict = dict(zip(crime_data['district'], crime_data['danger_label']))
    
    # ë™ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    dong_names = []
    if population_data is not None and 'dong_name' in population_data.columns:
        dong_names = population_data['dong_name'].tolist()
    
    # ì‹¤ì œ ë„ë¡œ ë…¸ë“œ ì¢Œí‘œ ì‚¬ìš© (í•µì‹¬ ë³€ê²½!)
    pedestrian_nodes = facilities.get('pedestrian_node', pd.DataFrame())
    pedestrian_links = facilities.get('pedestrian_links', pd.DataFrame())
    
    if len(pedestrian_nodes) > 0:
        print(f"   âœ… ì‹¤ì œ ë„ë¡œ ë…¸ë“œ ì¢Œí‘œ ì‚¬ìš©: {len(pedestrian_nodes):,} ë…¸ë“œ")
        # ë…¸ë“œì—ì„œ ìƒ˜í”Œë§
        sample_indices = np.random.choice(len(pedestrian_nodes), min(n_samples, len(pedestrian_nodes)), replace=False)
        sampled_nodes = pedestrian_nodes.iloc[sample_indices].copy()
        
        # ë…¸ë“œì— í•´ë‹¹í•˜ëŠ” ë§í¬ ì •ë³´ ì¡°ì¸ (ë„ë¡œ ê¸¸ì´ ë“±)
        if len(pedestrian_links) > 0:
            node_link_info = pedestrian_links.groupby('start_node').agg({
                'length': 'mean',
                'crosswalk': 'max',
                'park': 'max',
                'tunnel': 'max'
            }).reset_index()
            sampled_nodes = sampled_nodes.merge(node_link_info, left_on='node_id', right_on='start_node', how='left')
    else:
        # í´ë°±: ëœë¤ ì¢Œí‘œ (ë„ë³´ ë°ì´í„° ì—†ì„ ê²½ìš°)
        print("   âš ï¸ ë„ë³´ ë„¤íŠ¸ì›Œí¬ ë°ì´í„° ì—†ìŒ, ëœë¤ ì¢Œí‘œ ì‚¬ìš©")
        lat_range = (37.45, 37.70)
        lon_range = (126.80, 127.15)
        sampled_nodes = pd.DataFrame({
            'latitude': np.random.uniform(*lat_range, n_samples),
            'longitude': np.random.uniform(*lon_range, n_samples),
            'dong': None,
            'length': np.random.exponential(100, n_samples) + 10
        })
    
    np.random.seed(42)
    samples = []
    
    for idx, row in sampled_nodes.iterrows():
        lat = row['latitude']
        lon = row['longitude']
        
        # ì‹¤ì œ ë„ë¡œ ê¸¸ì´ ì‚¬ìš© (ìˆìœ¼ë©´)
        road_length = row.get('length', 100)
        if pd.isna(road_length):
            road_length = 100
        road_length = min(road_length, 500)
        
        is_main_road = np.random.random() < 0.2
        
        # ë™ ì´ë¦„ (ë…¸ë“œì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ëœë¤)
        dong_name = row.get('dong', None)
        if pd.isna(dong_name) and dong_names:
            dong_name = np.random.choice(dong_names)
        
        # ëœë¤ ì‹œê°„/ìš”ì¼ (í•™ìŠµ ë°ì´í„° ë‹¤ì–‘ì„±)
        hour = np.random.randint(0, 24)
        day_of_week = np.random.randint(0, 7)  # 0=ì›”~6=ì¼
        
        # í”¼ì²˜ ì¶”ì¶œ
        features = extractor.extract_features(lat, lon, road_length, is_main_road, 
                                              dong_name=dong_name)
        
        # ì‹œê°„/ìš”ì¼ í”¼ì²˜ ì¶”ê°€
        features['hour_danger'] = get_time_danger_score(hour, time_danger)
        features['day_danger'] = get_day_danger_score(day_of_week, day_danger)
        features['is_night'] = 1 if (hour < 6 or hour >= 21) else 0
        features['is_weekend'] = 1 if day_of_week >= 5 else 0
        
        # ê°€ë¡œë“± ON/OFF í”¼ì²˜ ì¶”ê°€
        if streetlight_schedule:
            sl_on = is_streetlight_on(hour, streetlight_schedule)
            features['streetlight_on'] = 1 if sl_on else 0
            # ê°€ë¡œë“± êº¼ì§„ ì‹œê°„ì—ëŠ” ê°€ë¡œë“± íš¨ê³¼ ë¬´íš¨í™”
            if not sl_on:
                features['streetlight_effective_count'] = 0
                features['streetlight_effective_proximity'] = 0
            else:
                features['streetlight_effective_count'] = features['streetlight_count']
                features['streetlight_effective_proximity'] = features['streetlight_proximity']
        else:
            features['streetlight_on'] = 1
            features['streetlight_effective_count'] = features['streetlight_count']
            features['streetlight_effective_proximity'] = features['streetlight_proximity']
        
        district = get_district_from_coords(lat, lon)
        base_danger = danger_dict.get(district, 0.5)
        
        # ìœ„í—˜ë„ ì¡°ì •
        adjusted_danger = base_danger
        adjusted_danger += features['isolation_score'] * 0.2
        adjusted_danger += features['complete_isolation'] * 0.3
        
        # ê°€ë¡œë“± íš¨ê³¼ (ì ë“± ìƒíƒœì— ë”°ë¼)
        adjusted_danger -= features['streetlight_effective_proximity'] * 0.1
        
        adjusted_danger -= features['cctv_proximity'] * 0.15
        adjusted_danger -= features['convenience_proximity'] * 0.1
        adjusted_danger -= features['police_proximity'] * 0.1
        adjusted_danger += features['entertainment_danger'] * 0.25
        
        # ìƒí™œì¸êµ¬ ë°˜ì˜
        adjusted_danger += features['low_population'] * 0.15
        adjusted_danger -= features['high_population'] * 0.1
        adjusted_danger += features['night_isolation'] * 0.2
        
        # ì‹œê°„/ìš”ì¼ ë°˜ì˜
        adjusted_danger += features['hour_danger'] * 0.2  # ì‹œê°„ëŒ€ ìœ„í—˜ë„ ë°˜ì˜
        adjusted_danger += features['day_danger'] * 0.1   # ìš”ì¼ ìœ„í—˜ë„ ë°˜ì˜
        adjusted_danger += features['is_night'] * 0.15    # ì•¼ê°„ ì¶”ê°€ ìœ„í—˜
        adjusted_danger += features['is_weekend'] * 0.05  # ì£¼ë§ ì¶”ê°€
        
        if is_main_road:
            adjusted_danger -= 0.1
        
        adjusted_danger = np.clip(adjusted_danger + np.random.normal(0, 0.05), 0, 1)
        
        sample = {
            'latitude': lat,
            'longitude': lon,
            'district': district,
            'hour': hour,
            'day_of_week': day_of_week,
            **features,
            'danger_label': adjusted_danger
        }
        samples.append(sample)
    
    df = pd.DataFrame(samples)
    print(f"âœ… í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(df)} ìƒ˜í”Œ")
    
    return df


# ============================================
# ë©”ì¸ ì‹¤í–‰
# ============================================

def train_and_save_model():
    """ëª¨ë¸ í•™ìŠµ ë° ì €ì¥"""
    print("=" * 60)
    print("ğŸš€ í–¥ìƒëœ ML ëª¨ë¸ í•™ìŠµ (ìƒí™œì¸êµ¬ + ì‹œê°„/ìš”ì¼ í¬í•¨)")
    print("=" * 60)
    
    # 1. ë²”ì£„ ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë²”ì£„ ë°ì´í„° ë¡œë“œ...")
    crime_data = load_crime_data()
    
    if len(crime_data) == 0:
        print("âŒ ë²”ì£„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    PROCESSED_DIR.mkdir(exist_ok=True)
    crime_data.to_csv(PROCESSED_DIR / "crime_by_district.csv", index=False, encoding='utf-8-sig')
    
    # 2. ìƒí™œì¸êµ¬ ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ìƒí™œì¸êµ¬ ë°ì´í„° ë¡œë“œ...")
    population_data = load_population_data()
    
    if len(population_data) > 0:
        population_data.to_csv(PROCESSED_DIR / "population_by_dong.csv", index=False, encoding='utf-8-sig')
    
    # 3. ë²”ì£„ ì‹œê°„/ìš”ì¼ ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë²”ì£„ ì‹œê°„/ìš”ì¼ ë°ì´í„° ë¡œë“œ...")
    time_danger = load_crime_time_data()
    day_danger = load_crime_day_data()
    
    # 4. ê°€ë¡œë“± ì ì†Œë“± ì‹œê°„ ë¡œë“œ
    print("\nğŸ“‚ ê°€ë¡œë“± ì ì†Œë“± ì‹œê°„ ë¡œë“œ...")
    streetlight_schedule = load_streetlight_schedule()
    
    # 5. ì‹œì„¤ë¬¼ ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ì‹œì„¤ë¬¼ ë°ì´í„° ë¡œë“œ...")
    facilities = load_facility_data()
    
    for key, df in facilities.items():
        if len(df) > 0:
            print(f"   {key}: {len(df):,} ê±´")
    
    # 6. í•™ìŠµ ë°ì´í„° ìƒì„± (ì‹œê°„/ìš”ì¼ + ê°€ë¡œë“± ì ì†Œë“± í¬í•¨)
    training_data = generate_training_data(
        crime_data, facilities, population_data, 
        time_danger, day_danger, streetlight_schedule, n_samples=10000
    )
    
    # 6. ëª¨ë¸ í•™ìŠµ
    use_population = len(population_data) > 0
    use_time = time_danger is not None
    use_safety_zone = 'school' in facilities and len(facilities.get('school', [])) > 0
    
    model = EnhancedSafetyMLModel(
        use_all_features=True, 
        use_population=use_population, 
        use_time=use_time,
        use_safety_zone=use_safety_zone
    )
    metrics = model.train(training_data)
    
    # 7. ëª¨ë¸ ì €ì¥
    model.save("enhanced_safety_model")
    model.save("safety_ml_model")
    
    print("\n" + "=" * 60)
    print("âœ… í–¥ìƒëœ ML ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print(f"   RÂ² ì„±ëŠ¥: {metrics['r2']:.4f}")
    if use_population:
        print("   ğŸ“Š ìƒí™œì¸êµ¬ í”¼ì²˜ í¬í•¨ë¨!")
    if use_time:
        print("   â° ì‹œê°„/ìš”ì¼ í”¼ì²˜ í¬í•¨ë¨!")
    print("=" * 60)
    
    return model


if __name__ == "__main__":
    train_and_save_model()
